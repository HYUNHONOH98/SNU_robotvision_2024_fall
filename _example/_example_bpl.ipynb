{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/hyunho/sfda/\")\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrained_source_model_path = \"exp/deeplabv2_1024/best_model_4_accuracy=0.8350.pt\"\n",
    "import os\n",
    "pretrained_source_model_path= os.path.join(\"/home/hyunho/sfda\", pretrained_source_model_path)\n",
    "print(f\"device : {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from model.deeplabv2 import ResNetMulti, Bottleneck, ThresholdNet\n",
    "\n",
    "class ResNetMultiBayes(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super(ResNetMultiBayes, self).__init__()\n",
    "        self.resnet = ResNetMulti(block, layers, num_classes)\n",
    "        self.thresholdnet = ThresholdNet(2048 ,256) # input size, output size\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((19,1)) # class num?\n",
    "\n",
    "    def forward(self, x,):\n",
    "        output, feature = self.resnet(x, return_features=True)\n",
    "        feature = self.avgpool(feature)\n",
    "        mu, logvar = self.thresholdnet(torch.squeeze(feature, dim=-1).permute(0,2,1))\n",
    "\n",
    "        # return torch.squeeze(feature,dim=-1)\n",
    "        return output, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetMultiBayes(Bottleneck, layers= [3, 4, 6, 3], num_classes=19).to(device)\n",
    "model.resnet.load_state_dict(torch.load(pretrained_source_model_path, map_location=device, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunho/miniconda3/envs/test/lib/python3.8/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.cityscapes_loader import CityscapesDataset\n",
    "from torchvision import transforms\n",
    "from utils.data_augmentation import RandomResizedCropWithMask, RandomHorizontalFlip, rotate_image\n",
    "\n",
    "cityscape_image_mean = (0.4422, 0.4379, 0.4246)\n",
    "cityscape_image_std = (0.2572, 0.2516, 0.2467)\n",
    "input_size = (720, 1280)\n",
    "\n",
    "train_image_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=cityscape_image_mean, std=cityscape_image_std),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)]),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=5)])\n",
    "])\n",
    "valid_image_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=cityscape_image_mean, std=cityscape_image_std),\n",
    "])\n",
    "train_both_transforms = transforms.Compose([\n",
    "    RandomHorizontalFlip(0.5),\n",
    "    RandomResizedCropWithMask(input_size)\n",
    "    ])\n",
    "\n",
    "train_dataset = CityscapesDataset(\n",
    "    images_dir=\"/home/hyunho/sfda/data/cityscapes_dataset/leftImg8bit/train\",\n",
    "    masks_dir=\"/home/hyunho/sfda/data/cityscapes_dataset/gtFine/train\",\n",
    "    image_transform=train_image_transforms,\n",
    "    both_transform=train_both_transforms,\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=16\n",
    ")\n",
    "data = next(iter(train_loader))\n",
    "img, label, name = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunho/miniconda3/envs/test/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "img = img.to(device)\n",
    "output, mu, var  = model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Degbgging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loss import kld_loss\n",
    "loss, threshold = kld_loss(mu, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  9412.529296875\n",
      "threshold :  tensor([ 0.2881,  0.0449,  0.0340,  0.1194,  0.0490,  0.0780,  0.1539,  0.0614,\n",
      "         0.0861,  0.0945,  0.0566,  0.0450,  0.0168,  0.0678,  0.0710,  0.0914,\n",
      "        -0.0100,  0.0539,  0.1351], device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(\"loss : \", loss.item())\n",
    "print(\"threshold : \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from utils.loss import SoftDiceLoss, softmax_cross_entropy_with_logits\n",
    "\n",
    "def calculate_pseudo_loss(teacher_output,\n",
    "                          student_output,\n",
    "                          threshold,\n",
    "                          temp):\n",
    "\n",
    "    stu_prob_output = torch.softmax(student_output, dim=1)\n",
    "    tut_prob_output = torch.softmax(teacher_output, dim=1)\n",
    "    max_prob, max_class = tut_prob_output.max(dim=1)\n",
    "    threshold_map = threshold[max_class]\n",
    "    pseudo_labels = max_class.clone()\n",
    "    pseudo_labels[max_prob < threshold_map] = 255\n",
    "    background_mask = (pseudo_labels != 255).long()\n",
    "\n",
    "    pseudo_labels = pseudo_labels.float()\n",
    "\n",
    "    # for unlabelled parts:\n",
    "    if len(pseudo_labels.size()) == 3:\n",
    "        (b, h, w) = pseudo_labels.size()\n",
    "        vol = b*h*w\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if pseudo_labels.sum() > 0.0005*vol:\n",
    "        loss_unsup = 0.5*SoftDiceLoss()(stu_prob_output, pseudo_labels, background_mask)\n",
    "        loss_unsup += 0.5*softmax_cross_entropy_with_logits(student_output, pseudo_labels)\n",
    "    else:\n",
    "        loss_unsup = torch.zeros(1).cuda()\n",
    "\n",
    "    return {'loss': loss_unsup,\n",
    "            'prob': stu_prob_output.mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunho/miniconda3/envs/test/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1158,0,0], thread: [39,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1158,0,0], thread: [40,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1135,0,0], thread: [40,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1158,0,0], thread: [102,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1158,0,0], thread: [103,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1158,0,0], thread: [104,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1158,0,0], thread: [105,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1158,0,0], thread: [106,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [0,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [1,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [2,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [3,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [14,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [15,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [16,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [17,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [918,0,0], thread: [18,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1625,0,0], thread: [1,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [760,0,0], thread: [32,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [760,0,0], thread: [33,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [760,0,0], thread: [47,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [760,0,0], thread: [48,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [760,0,0], thread: [31,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1434,0,0], thread: [71,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1434,0,0], thread: [38,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1434,0,0], thread: [39,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1724789116784/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [1434,0,0], thread: [40,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m tut, _, _  \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[0;32m----> 4\u001b[0m loss_ \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pseudo_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mcalculate_pseudo_loss\u001b[0;34m(teacher_output, student_output, threshold, temp)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pseudo_labels\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0005\u001b[39m\u001b[38;5;241m*\u001b[39mvol:\n\u001b[1;32m     27\u001b[0m     loss_unsup \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mSoftDiceLoss()(stu_prob_output, pseudo_labels, background_mask)\n\u001b[0;32m---> 28\u001b[0m     loss_unsup \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msoftmax_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpseudo_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     loss_unsup \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/sfda/utils/loss.py:221\u001b[0m, in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[0;34m(logits, labels, dim)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax_cross_entropy_with_logits\u001b[39m( logits,labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlabels\u001b[49m \u001b[38;5;241m*\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39mdim))\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_output = torch.softmax(output, dim=1)\n",
    "max_prob, max_class = prob_output.max(dim=1)\n",
    "threshold_map = threshold[max_class]\n",
    "result = max_class.clone()\n",
    "\n",
    "result[max_prob < threshold_map] = 255\n",
    "background_mask = (result != 255).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 19, 720, 1280])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_prob_output = torch.softmax(output, dim=1)\n",
    "stu_prob_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
