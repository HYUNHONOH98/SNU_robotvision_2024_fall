{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/home/hyunho/sfda/\"\n",
    "import sys\n",
    "sys.path.append(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunho/miniconda3/envs/test/lib/python3.8/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, mIoU, ConfusionMatrix\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine\n",
    "from dataset.gta_loader import SegmentationDataset\n",
    "from dataset.cityscapes_loader import CityscapesDataset\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((720,1280)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=(0.4422, 0.4379, 0.4246), std=(0.2572, 0.2516, 0.2467)),\n",
    "])\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.Resize((720,1280), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CityscapesDataset(\n",
    "    images_dir=\"/home/hyunho/sfda/data/cityscapes_dataset/leftImg8bit/train\",\n",
    "    masks_dir=\"/home/hyunho/sfda/data/cityscapes_dataset/gtFine/train\",\n",
    "    transform=image_transforms,\n",
    "    target_transform=mask_transforms,\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "img, label, name = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.deeplabv2 import DeeplabMulti\n",
    "model = DeeplabMulti(num_classes=19, pretrained=False)\n",
    "model.load_state_dict(\n",
    "  torch.load(\"/home/hyunho/sfda/exp/deeplabv2_1022/best_model_3_accuracy=0.8210.pt\", map_location=device, weights_only=True)\n",
    "  # torch.load(\"/home/hyunho/sfda/exp/deeplabv2_1022/best_model_4_accuracy=0.8218.pt\", map_location=device, weights_only=True)\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "temp_output = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        18, 255], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import filterfalse as  ifilterfalse\n",
    "\n",
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []    \n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / float(union))\n",
    "        ious.append(iou)\n",
    "    ious = [mean(x) for x in zip(*ious)] # mean accross images if per_image\n",
    "    return 100 * np.array(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, classes = temp_output.softmax(1).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.02415371,   0.        ,  68.94382682,   0.        ,\n",
       "         0.        ,   1.9728905 ,   0.        ,   0.        ,\n",
       "         6.44570929,   0.        ,  69.20268769,   0.        ,\n",
       "         0.        ,   7.99529264,   0.        ,   0.        ,\n",
       "       100.        , 100.        ,   0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = iou(classes, label.long(), C=19, ignore=255)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.925503192307822"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss = np.zeros(19)\n",
    "total_loss += loss\n",
    "\n",
    "np.mean(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.02415371,   0.        ,  68.94382682,   0.        ,\n",
       "         0.        ,   1.9728905 ,   0.        ,   0.        ,\n",
       "         6.44570929,   0.        ,  69.20268769,   0.        ,\n",
       "         0.        ,   7.99529264,   0.        ,   0.        ,\n",
       "       100.        , 100.        ,   0.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
