{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6308/1653038833.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weight = torch.load(\"/home/hyunho/sfda/swin_tiny_patch4_window7_224.pth\", map_location= device)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weight = torch.load(\"/home/hyunho/sfda/swin_tiny_patch4_window7_224.pth\", map_location= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight[\"model\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "patch_embed.norm.weight\n",
      "patch_embed.norm.bias\n",
      "layers.0.blocks.0.norm1.weight\n",
      "layers.0.blocks.0.norm1.bias\n",
      "layers.0.blocks.0.attn.qkv.weight\n",
      "layers.0.blocks.0.attn.qkv.bias\n",
      "layers.0.blocks.0.attn.proj.weight\n",
      "layers.0.blocks.0.attn.proj.bias\n",
      "layers.0.blocks.0.norm2.weight\n",
      "layers.0.blocks.0.norm2.bias\n",
      "layers.0.blocks.0.mlp.fc1.weight\n",
      "layers.0.blocks.0.mlp.fc1.bias\n",
      "layers.0.blocks.0.mlp.fc2.weight\n",
      "layers.0.blocks.0.mlp.fc2.bias\n",
      "layers.0.blocks.1.norm1.weight\n",
      "layers.0.blocks.1.norm1.bias\n",
      "layers.0.blocks.1.attn.qkv.weight\n",
      "layers.0.blocks.1.attn.qkv.bias\n",
      "layers.0.blocks.1.attn.proj.weight\n",
      "layers.0.blocks.1.attn.proj.bias\n",
      "layers.0.blocks.1.norm2.weight\n",
      "layers.0.blocks.1.norm2.bias\n",
      "layers.0.blocks.1.mlp.fc1.weight\n",
      "layers.0.blocks.1.mlp.fc1.bias\n",
      "layers.0.blocks.1.mlp.fc2.weight\n",
      "layers.0.blocks.1.mlp.fc2.bias\n",
      "layers.0.downsample.norm.weight\n",
      "layers.0.downsample.norm.bias\n",
      "layers.1.blocks.0.norm1.weight\n",
      "layers.1.blocks.0.norm1.bias\n",
      "layers.1.blocks.0.attn.qkv.weight\n",
      "layers.1.blocks.0.attn.qkv.bias\n",
      "layers.1.blocks.0.attn.proj.weight\n",
      "layers.1.blocks.0.attn.proj.bias\n",
      "layers.1.blocks.0.norm2.weight\n",
      "layers.1.blocks.0.norm2.bias\n",
      "layers.1.blocks.0.mlp.fc1.weight\n",
      "layers.1.blocks.0.mlp.fc1.bias\n",
      "layers.1.blocks.0.mlp.fc2.weight\n",
      "layers.1.blocks.0.mlp.fc2.bias\n",
      "layers.1.blocks.1.norm1.weight\n",
      "layers.1.blocks.1.norm1.bias\n",
      "layers.1.blocks.1.attn.qkv.weight\n",
      "layers.1.blocks.1.attn.qkv.bias\n",
      "layers.1.blocks.1.attn.proj.weight\n",
      "layers.1.blocks.1.attn.proj.bias\n",
      "layers.1.blocks.1.norm2.weight\n",
      "layers.1.blocks.1.norm2.bias\n",
      "layers.1.blocks.1.mlp.fc1.weight\n",
      "layers.1.blocks.1.mlp.fc1.bias\n",
      "layers.1.blocks.1.mlp.fc2.weight\n",
      "layers.1.blocks.1.mlp.fc2.bias\n",
      "layers.1.downsample.norm.weight\n",
      "layers.1.downsample.norm.bias\n",
      "layers.2.blocks.0.norm1.weight\n",
      "layers.2.blocks.0.norm1.bias\n",
      "layers.2.blocks.0.attn.qkv.weight\n",
      "layers.2.blocks.0.attn.qkv.bias\n",
      "layers.2.blocks.0.attn.proj.weight\n",
      "layers.2.blocks.0.attn.proj.bias\n",
      "layers.2.blocks.0.norm2.weight\n",
      "layers.2.blocks.0.norm2.bias\n",
      "layers.2.blocks.0.mlp.fc1.weight\n",
      "layers.2.blocks.0.mlp.fc1.bias\n",
      "layers.2.blocks.0.mlp.fc2.weight\n",
      "layers.2.blocks.0.mlp.fc2.bias\n",
      "layers.2.blocks.1.norm1.weight\n",
      "layers.2.blocks.1.norm1.bias\n",
      "layers.2.blocks.1.attn.qkv.weight\n",
      "layers.2.blocks.1.attn.qkv.bias\n",
      "layers.2.blocks.1.attn.proj.weight\n",
      "layers.2.blocks.1.attn.proj.bias\n",
      "layers.2.blocks.1.norm2.weight\n",
      "layers.2.blocks.1.norm2.bias\n",
      "layers.2.blocks.1.mlp.fc1.weight\n",
      "layers.2.blocks.1.mlp.fc1.bias\n",
      "layers.2.blocks.1.mlp.fc2.weight\n",
      "layers.2.blocks.1.mlp.fc2.bias\n",
      "layers.2.blocks.2.norm1.weight\n",
      "layers.2.blocks.2.norm1.bias\n",
      "layers.2.blocks.2.attn.qkv.weight\n",
      "layers.2.blocks.2.attn.qkv.bias\n",
      "layers.2.blocks.2.attn.proj.weight\n",
      "layers.2.blocks.2.attn.proj.bias\n",
      "layers.2.blocks.2.norm2.weight\n",
      "layers.2.blocks.2.norm2.bias\n",
      "layers.2.blocks.2.mlp.fc1.weight\n",
      "layers.2.blocks.2.mlp.fc1.bias\n",
      "layers.2.blocks.2.mlp.fc2.weight\n",
      "layers.2.blocks.2.mlp.fc2.bias\n",
      "layers.2.blocks.3.norm1.weight\n",
      "layers.2.blocks.3.norm1.bias\n",
      "layers.2.blocks.3.attn.qkv.weight\n",
      "layers.2.blocks.3.attn.qkv.bias\n",
      "layers.2.blocks.3.attn.proj.weight\n",
      "layers.2.blocks.3.attn.proj.bias\n",
      "layers.2.blocks.3.norm2.weight\n",
      "layers.2.blocks.3.norm2.bias\n",
      "layers.2.blocks.3.mlp.fc1.weight\n",
      "layers.2.blocks.3.mlp.fc1.bias\n",
      "layers.2.blocks.3.mlp.fc2.weight\n",
      "layers.2.blocks.3.mlp.fc2.bias\n",
      "layers.2.blocks.4.norm1.weight\n",
      "layers.2.blocks.4.norm1.bias\n",
      "layers.2.blocks.4.attn.qkv.weight\n",
      "layers.2.blocks.4.attn.qkv.bias\n",
      "layers.2.blocks.4.attn.proj.weight\n",
      "layers.2.blocks.4.attn.proj.bias\n",
      "layers.2.blocks.4.norm2.weight\n",
      "layers.2.blocks.4.norm2.bias\n",
      "layers.2.blocks.4.mlp.fc1.weight\n",
      "layers.2.blocks.4.mlp.fc1.bias\n",
      "layers.2.blocks.4.mlp.fc2.weight\n",
      "layers.2.blocks.4.mlp.fc2.bias\n",
      "layers.2.blocks.5.norm1.weight\n",
      "layers.2.blocks.5.norm1.bias\n",
      "layers.2.blocks.5.attn.qkv.weight\n",
      "layers.2.blocks.5.attn.qkv.bias\n",
      "layers.2.blocks.5.attn.proj.weight\n",
      "layers.2.blocks.5.attn.proj.bias\n",
      "layers.2.blocks.5.norm2.weight\n",
      "layers.2.blocks.5.norm2.bias\n",
      "layers.2.blocks.5.mlp.fc1.weight\n",
      "layers.2.blocks.5.mlp.fc1.bias\n",
      "layers.2.blocks.5.mlp.fc2.weight\n",
      "layers.2.blocks.5.mlp.fc2.bias\n",
      "layers.2.downsample.norm.weight\n",
      "layers.2.downsample.norm.bias\n",
      "layers.3.blocks.0.norm1.weight\n",
      "layers.3.blocks.0.norm1.bias\n",
      "layers.3.blocks.0.attn.qkv.weight\n",
      "layers.3.blocks.0.attn.qkv.bias\n",
      "layers.3.blocks.0.attn.proj.weight\n",
      "layers.3.blocks.0.attn.proj.bias\n",
      "layers.3.blocks.0.norm2.weight\n",
      "layers.3.blocks.0.norm2.bias\n",
      "layers.3.blocks.0.mlp.fc1.weight\n",
      "layers.3.blocks.0.mlp.fc1.bias\n",
      "layers.3.blocks.0.mlp.fc2.weight\n",
      "layers.3.blocks.0.mlp.fc2.bias\n",
      "layers.3.blocks.1.norm1.weight\n",
      "layers.3.blocks.1.norm1.bias\n",
      "layers.3.blocks.1.attn.qkv.weight\n",
      "layers.3.blocks.1.attn.qkv.bias\n",
      "layers.3.blocks.1.attn.proj.weight\n",
      "layers.3.blocks.1.attn.proj.bias\n",
      "layers.3.blocks.1.norm2.weight\n",
      "layers.3.blocks.1.norm2.bias\n",
      "layers.3.blocks.1.mlp.fc1.weight\n",
      "layers.3.blocks.1.mlp.fc1.bias\n",
      "layers.3.blocks.1.mlp.fc2.weight\n",
      "layers.3.blocks.1.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.weight\n",
      "head.bias\n",
      "layers.0.blocks.0.attn.relative_position_index\n",
      "layers.0.blocks.1.attn.relative_position_index\n",
      "layers.1.blocks.0.attn.relative_position_index\n",
      "layers.1.blocks.1.attn.relative_position_index\n",
      "layers.2.blocks.0.attn.relative_position_index\n",
      "layers.2.blocks.1.attn.relative_position_index\n",
      "layers.2.blocks.2.attn.relative_position_index\n",
      "layers.2.blocks.3.attn.relative_position_index\n",
      "layers.2.blocks.4.attn.relative_position_index\n",
      "layers.2.blocks.5.attn.relative_position_index\n",
      "layers.3.blocks.0.attn.relative_position_index\n",
      "layers.3.blocks.1.attn.relative_position_index\n",
      "layers.0.blocks.1.attn_mask\n",
      "layers.1.blocks.1.attn_mask\n",
      "layers.2.blocks.1.attn_mask\n",
      "layers.2.blocks.3.attn_mask\n",
      "layers.2.blocks.5.attn_mask\n",
      "layers.0.blocks.0.attn.relative_position_bias_table\n",
      "layers.0.blocks.1.attn.relative_position_bias_table\n",
      "layers.1.blocks.0.attn.relative_position_bias_table\n",
      "layers.1.blocks.1.attn.relative_position_bias_table\n",
      "layers.2.blocks.0.attn.relative_position_bias_table\n",
      "layers.2.blocks.1.attn.relative_position_bias_table\n",
      "layers.2.blocks.2.attn.relative_position_bias_table\n",
      "layers.2.blocks.3.attn.relative_position_bias_table\n",
      "layers.2.blocks.4.attn.relative_position_bias_table\n",
      "layers.2.blocks.5.attn.relative_position_bias_table\n",
      "layers.3.blocks.0.attn.relative_position_bias_table\n",
      "layers.3.blocks.1.attn.relative_position_bias_table\n",
      "layers.0.downsample.reduction.weight\n",
      "layers.1.downsample.reduction.weight\n",
      "layers.2.downsample.reduction.weight\n"
     ]
    }
   ],
   "source": [
    "for i in weight[\"model\"].keys():\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Mask2FormerConfig, Mask2FormerModel, Mask2FormerForUniversalSegmentation, AutoImageProcessor\n",
    "cfg = Mask2FormerConfig()\n",
    "cfg.backbone_config.depths = [2, 2, 6, 2]\n",
    "model = Mask2FormerForUniversalSegmentation(cfg).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mask2FormerTransformerModule(\n",
       "  (position_embedder): Mask2FormerSinePositionEmbedding()\n",
       "  (queries_embedder): Embedding(100, 256)\n",
       "  (queries_features): Embedding(100, 256)\n",
       "  (decoder): Mask2FormerMaskedAttentionDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-8): 9 x Mask2FormerMaskedAttentionDecoderLayer(\n",
       "        (self_attn): Mask2FormerAttention(\n",
       "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (activation_fn): ReLU()\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (cross_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (mask_predictor): Mask2FormerMaskPredictor(\n",
       "      (mask_embedder): Mask2FormerMLPPredictionHead(\n",
       "        (0): Mask2FormerPredictionBlock(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Mask2FormerPredictionBlock(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Mask2FormerPredictionBlock(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (level_embed): Embedding(3, 256)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.transformer_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.model.pixel_level_module.encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.patch_embeddings.projection.weight\n",
      "embeddings.patch_embeddings.projection.bias\n",
      "embeddings.norm.weight\n",
      "embeddings.norm.bias\n",
      "encoder.layers.0.blocks.0.layernorm_before.weight\n",
      "encoder.layers.0.blocks.0.layernorm_before.bias\n",
      "encoder.layers.0.blocks.0.attention.self.relative_position_bias_table\n",
      "encoder.layers.0.blocks.0.attention.self.relative_position_index\n",
      "encoder.layers.0.blocks.0.attention.self.query.weight\n",
      "encoder.layers.0.blocks.0.attention.self.query.bias\n",
      "encoder.layers.0.blocks.0.attention.self.key.weight\n",
      "encoder.layers.0.blocks.0.attention.self.key.bias\n",
      "encoder.layers.0.blocks.0.attention.self.value.weight\n",
      "encoder.layers.0.blocks.0.attention.self.value.bias\n",
      "encoder.layers.0.blocks.0.attention.output.dense.weight\n",
      "encoder.layers.0.blocks.0.attention.output.dense.bias\n",
      "encoder.layers.0.blocks.0.layernorm_after.weight\n",
      "encoder.layers.0.blocks.0.layernorm_after.bias\n",
      "encoder.layers.0.blocks.0.intermediate.dense.weight\n",
      "encoder.layers.0.blocks.0.intermediate.dense.bias\n",
      "encoder.layers.0.blocks.0.output.dense.weight\n",
      "encoder.layers.0.blocks.0.output.dense.bias\n",
      "encoder.layers.0.blocks.1.layernorm_before.weight\n",
      "encoder.layers.0.blocks.1.layernorm_before.bias\n",
      "encoder.layers.0.blocks.1.attention.self.relative_position_bias_table\n",
      "encoder.layers.0.blocks.1.attention.self.relative_position_index\n",
      "encoder.layers.0.blocks.1.attention.self.query.weight\n",
      "encoder.layers.0.blocks.1.attention.self.query.bias\n",
      "encoder.layers.0.blocks.1.attention.self.key.weight\n",
      "encoder.layers.0.blocks.1.attention.self.key.bias\n",
      "encoder.layers.0.blocks.1.attention.self.value.weight\n",
      "encoder.layers.0.blocks.1.attention.self.value.bias\n",
      "encoder.layers.0.blocks.1.attention.output.dense.weight\n",
      "encoder.layers.0.blocks.1.attention.output.dense.bias\n",
      "encoder.layers.0.blocks.1.layernorm_after.weight\n",
      "encoder.layers.0.blocks.1.layernorm_after.bias\n",
      "encoder.layers.0.blocks.1.intermediate.dense.weight\n",
      "encoder.layers.0.blocks.1.intermediate.dense.bias\n",
      "encoder.layers.0.blocks.1.output.dense.weight\n",
      "encoder.layers.0.blocks.1.output.dense.bias\n",
      "encoder.layers.0.downsample.reduction.weight\n",
      "encoder.layers.0.downsample.norm.weight\n",
      "encoder.layers.0.downsample.norm.bias\n",
      "encoder.layers.1.blocks.0.layernorm_before.weight\n",
      "encoder.layers.1.blocks.0.layernorm_before.bias\n",
      "encoder.layers.1.blocks.0.attention.self.relative_position_bias_table\n",
      "encoder.layers.1.blocks.0.attention.self.relative_position_index\n",
      "encoder.layers.1.blocks.0.attention.self.query.weight\n",
      "encoder.layers.1.blocks.0.attention.self.query.bias\n",
      "encoder.layers.1.blocks.0.attention.self.key.weight\n",
      "encoder.layers.1.blocks.0.attention.self.key.bias\n",
      "encoder.layers.1.blocks.0.attention.self.value.weight\n",
      "encoder.layers.1.blocks.0.attention.self.value.bias\n",
      "encoder.layers.1.blocks.0.attention.output.dense.weight\n",
      "encoder.layers.1.blocks.0.attention.output.dense.bias\n",
      "encoder.layers.1.blocks.0.layernorm_after.weight\n",
      "encoder.layers.1.blocks.0.layernorm_after.bias\n",
      "encoder.layers.1.blocks.0.intermediate.dense.weight\n",
      "encoder.layers.1.blocks.0.intermediate.dense.bias\n",
      "encoder.layers.1.blocks.0.output.dense.weight\n",
      "encoder.layers.1.blocks.0.output.dense.bias\n",
      "encoder.layers.1.blocks.1.layernorm_before.weight\n",
      "encoder.layers.1.blocks.1.layernorm_before.bias\n",
      "encoder.layers.1.blocks.1.attention.self.relative_position_bias_table\n",
      "encoder.layers.1.blocks.1.attention.self.relative_position_index\n",
      "encoder.layers.1.blocks.1.attention.self.query.weight\n",
      "encoder.layers.1.blocks.1.attention.self.query.bias\n",
      "encoder.layers.1.blocks.1.attention.self.key.weight\n",
      "encoder.layers.1.blocks.1.attention.self.key.bias\n",
      "encoder.layers.1.blocks.1.attention.self.value.weight\n",
      "encoder.layers.1.blocks.1.attention.self.value.bias\n",
      "encoder.layers.1.blocks.1.attention.output.dense.weight\n",
      "encoder.layers.1.blocks.1.attention.output.dense.bias\n",
      "encoder.layers.1.blocks.1.layernorm_after.weight\n",
      "encoder.layers.1.blocks.1.layernorm_after.bias\n",
      "encoder.layers.1.blocks.1.intermediate.dense.weight\n",
      "encoder.layers.1.blocks.1.intermediate.dense.bias\n",
      "encoder.layers.1.blocks.1.output.dense.weight\n",
      "encoder.layers.1.blocks.1.output.dense.bias\n",
      "encoder.layers.1.downsample.reduction.weight\n",
      "encoder.layers.1.downsample.norm.weight\n",
      "encoder.layers.1.downsample.norm.bias\n",
      "encoder.layers.2.blocks.0.layernorm_before.weight\n",
      "encoder.layers.2.blocks.0.layernorm_before.bias\n",
      "encoder.layers.2.blocks.0.attention.self.relative_position_bias_table\n",
      "encoder.layers.2.blocks.0.attention.self.relative_position_index\n",
      "encoder.layers.2.blocks.0.attention.self.query.weight\n",
      "encoder.layers.2.blocks.0.attention.self.query.bias\n",
      "encoder.layers.2.blocks.0.attention.self.key.weight\n",
      "encoder.layers.2.blocks.0.attention.self.key.bias\n",
      "encoder.layers.2.blocks.0.attention.self.value.weight\n",
      "encoder.layers.2.blocks.0.attention.self.value.bias\n",
      "encoder.layers.2.blocks.0.attention.output.dense.weight\n",
      "encoder.layers.2.blocks.0.attention.output.dense.bias\n",
      "encoder.layers.2.blocks.0.layernorm_after.weight\n",
      "encoder.layers.2.blocks.0.layernorm_after.bias\n",
      "encoder.layers.2.blocks.0.intermediate.dense.weight\n",
      "encoder.layers.2.blocks.0.intermediate.dense.bias\n",
      "encoder.layers.2.blocks.0.output.dense.weight\n",
      "encoder.layers.2.blocks.0.output.dense.bias\n",
      "encoder.layers.2.blocks.1.layernorm_before.weight\n",
      "encoder.layers.2.blocks.1.layernorm_before.bias\n",
      "encoder.layers.2.blocks.1.attention.self.relative_position_bias_table\n",
      "encoder.layers.2.blocks.1.attention.self.relative_position_index\n",
      "encoder.layers.2.blocks.1.attention.self.query.weight\n",
      "encoder.layers.2.blocks.1.attention.self.query.bias\n",
      "encoder.layers.2.blocks.1.attention.self.key.weight\n",
      "encoder.layers.2.blocks.1.attention.self.key.bias\n",
      "encoder.layers.2.blocks.1.attention.self.value.weight\n",
      "encoder.layers.2.blocks.1.attention.self.value.bias\n",
      "encoder.layers.2.blocks.1.attention.output.dense.weight\n",
      "encoder.layers.2.blocks.1.attention.output.dense.bias\n",
      "encoder.layers.2.blocks.1.layernorm_after.weight\n",
      "encoder.layers.2.blocks.1.layernorm_after.bias\n",
      "encoder.layers.2.blocks.1.intermediate.dense.weight\n",
      "encoder.layers.2.blocks.1.intermediate.dense.bias\n",
      "encoder.layers.2.blocks.1.output.dense.weight\n",
      "encoder.layers.2.blocks.1.output.dense.bias\n",
      "encoder.layers.2.blocks.2.layernorm_before.weight\n",
      "encoder.layers.2.blocks.2.layernorm_before.bias\n",
      "encoder.layers.2.blocks.2.attention.self.relative_position_bias_table\n",
      "encoder.layers.2.blocks.2.attention.self.relative_position_index\n",
      "encoder.layers.2.blocks.2.attention.self.query.weight\n",
      "encoder.layers.2.blocks.2.attention.self.query.bias\n",
      "encoder.layers.2.blocks.2.attention.self.key.weight\n",
      "encoder.layers.2.blocks.2.attention.self.key.bias\n",
      "encoder.layers.2.blocks.2.attention.self.value.weight\n",
      "encoder.layers.2.blocks.2.attention.self.value.bias\n",
      "encoder.layers.2.blocks.2.attention.output.dense.weight\n",
      "encoder.layers.2.blocks.2.attention.output.dense.bias\n",
      "encoder.layers.2.blocks.2.layernorm_after.weight\n",
      "encoder.layers.2.blocks.2.layernorm_after.bias\n",
      "encoder.layers.2.blocks.2.intermediate.dense.weight\n",
      "encoder.layers.2.blocks.2.intermediate.dense.bias\n",
      "encoder.layers.2.blocks.2.output.dense.weight\n",
      "encoder.layers.2.blocks.2.output.dense.bias\n",
      "encoder.layers.2.blocks.3.layernorm_before.weight\n",
      "encoder.layers.2.blocks.3.layernorm_before.bias\n",
      "encoder.layers.2.blocks.3.attention.self.relative_position_bias_table\n",
      "encoder.layers.2.blocks.3.attention.self.relative_position_index\n",
      "encoder.layers.2.blocks.3.attention.self.query.weight\n",
      "encoder.layers.2.blocks.3.attention.self.query.bias\n",
      "encoder.layers.2.blocks.3.attention.self.key.weight\n",
      "encoder.layers.2.blocks.3.attention.self.key.bias\n",
      "encoder.layers.2.blocks.3.attention.self.value.weight\n",
      "encoder.layers.2.blocks.3.attention.self.value.bias\n",
      "encoder.layers.2.blocks.3.attention.output.dense.weight\n",
      "encoder.layers.2.blocks.3.attention.output.dense.bias\n",
      "encoder.layers.2.blocks.3.layernorm_after.weight\n",
      "encoder.layers.2.blocks.3.layernorm_after.bias\n",
      "encoder.layers.2.blocks.3.intermediate.dense.weight\n",
      "encoder.layers.2.blocks.3.intermediate.dense.bias\n",
      "encoder.layers.2.blocks.3.output.dense.weight\n",
      "encoder.layers.2.blocks.3.output.dense.bias\n",
      "encoder.layers.2.blocks.4.layernorm_before.weight\n",
      "encoder.layers.2.blocks.4.layernorm_before.bias\n",
      "encoder.layers.2.blocks.4.attention.self.relative_position_bias_table\n",
      "encoder.layers.2.blocks.4.attention.self.relative_position_index\n",
      "encoder.layers.2.blocks.4.attention.self.query.weight\n",
      "encoder.layers.2.blocks.4.attention.self.query.bias\n",
      "encoder.layers.2.blocks.4.attention.self.key.weight\n",
      "encoder.layers.2.blocks.4.attention.self.key.bias\n",
      "encoder.layers.2.blocks.4.attention.self.value.weight\n",
      "encoder.layers.2.blocks.4.attention.self.value.bias\n",
      "encoder.layers.2.blocks.4.attention.output.dense.weight\n",
      "encoder.layers.2.blocks.4.attention.output.dense.bias\n",
      "encoder.layers.2.blocks.4.layernorm_after.weight\n",
      "encoder.layers.2.blocks.4.layernorm_after.bias\n",
      "encoder.layers.2.blocks.4.intermediate.dense.weight\n",
      "encoder.layers.2.blocks.4.intermediate.dense.bias\n",
      "encoder.layers.2.blocks.4.output.dense.weight\n",
      "encoder.layers.2.blocks.4.output.dense.bias\n",
      "encoder.layers.2.blocks.5.layernorm_before.weight\n",
      "encoder.layers.2.blocks.5.layernorm_before.bias\n",
      "encoder.layers.2.blocks.5.attention.self.relative_position_bias_table\n",
      "encoder.layers.2.blocks.5.attention.self.relative_position_index\n",
      "encoder.layers.2.blocks.5.attention.self.query.weight\n",
      "encoder.layers.2.blocks.5.attention.self.query.bias\n",
      "encoder.layers.2.blocks.5.attention.self.key.weight\n",
      "encoder.layers.2.blocks.5.attention.self.key.bias\n",
      "encoder.layers.2.blocks.5.attention.self.value.weight\n",
      "encoder.layers.2.blocks.5.attention.self.value.bias\n",
      "encoder.layers.2.blocks.5.attention.output.dense.weight\n",
      "encoder.layers.2.blocks.5.attention.output.dense.bias\n",
      "encoder.layers.2.blocks.5.layernorm_after.weight\n",
      "encoder.layers.2.blocks.5.layernorm_after.bias\n",
      "encoder.layers.2.blocks.5.intermediate.dense.weight\n",
      "encoder.layers.2.blocks.5.intermediate.dense.bias\n",
      "encoder.layers.2.blocks.5.output.dense.weight\n",
      "encoder.layers.2.blocks.5.output.dense.bias\n",
      "encoder.layers.2.downsample.reduction.weight\n",
      "encoder.layers.2.downsample.norm.weight\n",
      "encoder.layers.2.downsample.norm.bias\n",
      "encoder.layers.3.blocks.0.layernorm_before.weight\n",
      "encoder.layers.3.blocks.0.layernorm_before.bias\n",
      "encoder.layers.3.blocks.0.attention.self.relative_position_bias_table\n",
      "encoder.layers.3.blocks.0.attention.self.relative_position_index\n",
      "encoder.layers.3.blocks.0.attention.self.query.weight\n",
      "encoder.layers.3.blocks.0.attention.self.query.bias\n",
      "encoder.layers.3.blocks.0.attention.self.key.weight\n",
      "encoder.layers.3.blocks.0.attention.self.key.bias\n",
      "encoder.layers.3.blocks.0.attention.self.value.weight\n",
      "encoder.layers.3.blocks.0.attention.self.value.bias\n",
      "encoder.layers.3.blocks.0.attention.output.dense.weight\n",
      "encoder.layers.3.blocks.0.attention.output.dense.bias\n",
      "encoder.layers.3.blocks.0.layernorm_after.weight\n",
      "encoder.layers.3.blocks.0.layernorm_after.bias\n",
      "encoder.layers.3.blocks.0.intermediate.dense.weight\n",
      "encoder.layers.3.blocks.0.intermediate.dense.bias\n",
      "encoder.layers.3.blocks.0.output.dense.weight\n",
      "encoder.layers.3.blocks.0.output.dense.bias\n",
      "encoder.layers.3.blocks.1.layernorm_before.weight\n",
      "encoder.layers.3.blocks.1.layernorm_before.bias\n",
      "encoder.layers.3.blocks.1.attention.self.relative_position_bias_table\n",
      "encoder.layers.3.blocks.1.attention.self.relative_position_index\n",
      "encoder.layers.3.blocks.1.attention.self.query.weight\n",
      "encoder.layers.3.blocks.1.attention.self.query.bias\n",
      "encoder.layers.3.blocks.1.attention.self.key.weight\n",
      "encoder.layers.3.blocks.1.attention.self.key.bias\n",
      "encoder.layers.3.blocks.1.attention.self.value.weight\n",
      "encoder.layers.3.blocks.1.attention.self.value.bias\n",
      "encoder.layers.3.blocks.1.attention.output.dense.weight\n",
      "encoder.layers.3.blocks.1.attention.output.dense.bias\n",
      "encoder.layers.3.blocks.1.layernorm_after.weight\n",
      "encoder.layers.3.blocks.1.layernorm_after.bias\n",
      "encoder.layers.3.blocks.1.intermediate.dense.weight\n",
      "encoder.layers.3.blocks.1.intermediate.dense.bias\n",
      "encoder.layers.3.blocks.1.output.dense.weight\n",
      "encoder.layers.3.blocks.1.output.dense.bias\n",
      "hidden_states_norms.stage1.weight\n",
      "hidden_states_norms.stage1.bias\n",
      "hidden_states_norms.stage2.weight\n",
      "hidden_states_norms.stage2.bias\n",
      "hidden_states_norms.stage3.weight\n",
      "hidden_states_norms.stage3.bias\n",
      "hidden_states_norms.stage4.weight\n",
      "hidden_states_norms.stage4.bias\n"
     ]
    }
   ],
   "source": [
    "for i in model.model.pixel_level_module.encoder.state_dict():\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query :  torch.Size([96, 96])\n",
      "key :  torch.Size([96, 96])\n",
      "value :  torch.Size([96, 96])\n"
     ]
    }
   ],
   "source": [
    "print(\"query : \", model.model.pixel_level_module.encoder.encoder.layers[0].blocks[0].attention.self.query.weight.shape)\n",
    "print(\"key : \", model.model.pixel_level_module.encoder.encoder.layers[0].blocks[0].attention.self.key.weight.shape)\n",
    "print(\"value : \", model.model.pixel_level_module.encoder.encoder.layers[0].blocks[0].attention.self.value.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.pixel_level_module.encoder.hidden_states_norms.stage1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mask2FormerPixelLevelModule(\n",
       "  (encoder): SwinBackbone(\n",
       "    (embeddings): SwinEmbeddings(\n",
       "      (patch_embeddings): SwinPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): SwinEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.3)\n",
       "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.3)\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-5): 6 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.3)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.3)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (hidden_states_norms): ModuleDict(\n",
       "      (stage1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (stage2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (stage3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (stage4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Mask2FormerPixelDecoder(\n",
       "    (position_embedding): Mask2FormerSinePositionEmbedding()\n",
       "    (input_projections): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder): Mask2FormerPixelDecoderEncoderOnly(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x Mask2FormerPixelDecoderEncoderLayer(\n",
       "          (self_attn): Mask2FormerPixelDecoderEncoderMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mask_projection): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (adapter_1): Sequential(\n",
       "      (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (layer_1): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.pixel_level_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm weight :  torch.Size([768])\n",
      "norm bias :  torch.Size([768])\n",
      "head weight :  torch.Size([1000, 768])\n",
      "head bias :  torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "print(\"norm weight : \",weight[\"model\"][\"norm.weight\"].shape)\n",
    "print(\"norm bias : \",weight[\"model\"][\"norm.bias\"].shape)\n",
    "print(\"head weight : \",weight[\"model\"][\"head.weight\"].shape)\n",
    "print(\"head bias : \",weight[\"model\"][\"head.bias\"].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6308/2471000216.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mseg_weight = torch.load(\"/home/hyunho/sfda/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "mseg_weight = torch.load(\"/home/hyunho/sfda/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mseg_weight.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layers = [x for x in model.state_dict().keys() if \"pixel_level_module.encoder\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pixel_level_module.encoder.embeddings.patch_embeddings.projection.weight\n",
      "model.pixel_level_module.encoder.embeddings.patch_embeddings.projection.bias\n",
      "model.pixel_level_module.encoder.embeddings.norm.weight\n",
      "model.pixel_level_module.encoder.embeddings.norm.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.0.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.blocks.1.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.0.downsample.reduction.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.downsample.norm.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.0.downsample.norm.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.0.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.blocks.1.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.1.downsample.reduction.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.downsample.norm.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.1.downsample.norm.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.0.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.1.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.2.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.3.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.4.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.blocks.5.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.2.downsample.reduction.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.downsample.norm.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.2.downsample.norm.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.0.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_before.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_before.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.relative_position_bias_table\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.relative_position_index\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.query.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.query.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.key.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.key.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.value.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.self.value.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.attention.output.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_after.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.layernorm_after.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.intermediate.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.intermediate.dense.bias\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.output.dense.weight\n",
      "model.pixel_level_module.encoder.encoder.layers.3.blocks.1.output.dense.bias\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage1.weight\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage1.bias\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage2.weight\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage2.bias\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage3.weight\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage3.bias\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage4.weight\n",
      "model.pixel_level_module.encoder.hidden_states_norms.stage4.bias\n"
     ]
    }
   ],
   "source": [
    "for i in selected_layers:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6308/14298589.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mmseg = torch.load('/home/hyunho/sfda/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "mmseg = torch.load('/home/hyunho/sfda/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.projection.weight\n",
      "patch_embed.projection.bias\n",
      "patch_embed.norm.weight\n",
      "patch_embed.norm.bias\n",
      "stages.0.blocks.0.norm1.weight\n",
      "stages.0.blocks.0.norm1.bias\n",
      "stages.0.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.0.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.0.blocks.0.attn.w_msa.proj.weight\n",
      "stages.0.blocks.0.attn.w_msa.proj.bias\n",
      "stages.0.blocks.0.norm2.weight\n",
      "stages.0.blocks.0.norm2.bias\n",
      "stages.0.blocks.0.ffn.layers.0.0.weight\n",
      "stages.0.blocks.0.ffn.layers.0.0.bias\n",
      "stages.0.blocks.0.ffn.layers.1.weight\n",
      "stages.0.blocks.0.ffn.layers.1.bias\n",
      "stages.0.blocks.1.norm1.weight\n",
      "stages.0.blocks.1.norm1.bias\n",
      "stages.0.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.0.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.0.blocks.1.attn.w_msa.proj.weight\n",
      "stages.0.blocks.1.attn.w_msa.proj.bias\n",
      "stages.0.blocks.1.norm2.weight\n",
      "stages.0.blocks.1.norm2.bias\n",
      "stages.0.blocks.1.ffn.layers.0.0.weight\n",
      "stages.0.blocks.1.ffn.layers.0.0.bias\n",
      "stages.0.blocks.1.ffn.layers.1.weight\n",
      "stages.0.blocks.1.ffn.layers.1.bias\n",
      "stages.0.downsample.norm.weight\n",
      "stages.0.downsample.norm.bias\n",
      "stages.1.blocks.0.norm1.weight\n",
      "stages.1.blocks.0.norm1.bias\n",
      "stages.1.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.1.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.1.blocks.0.attn.w_msa.proj.weight\n",
      "stages.1.blocks.0.attn.w_msa.proj.bias\n",
      "stages.1.blocks.0.norm2.weight\n",
      "stages.1.blocks.0.norm2.bias\n",
      "stages.1.blocks.0.ffn.layers.0.0.weight\n",
      "stages.1.blocks.0.ffn.layers.0.0.bias\n",
      "stages.1.blocks.0.ffn.layers.1.weight\n",
      "stages.1.blocks.0.ffn.layers.1.bias\n",
      "stages.1.blocks.1.norm1.weight\n",
      "stages.1.blocks.1.norm1.bias\n",
      "stages.1.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.1.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.1.blocks.1.attn.w_msa.proj.weight\n",
      "stages.1.blocks.1.attn.w_msa.proj.bias\n",
      "stages.1.blocks.1.norm2.weight\n",
      "stages.1.blocks.1.norm2.bias\n",
      "stages.1.blocks.1.ffn.layers.0.0.weight\n",
      "stages.1.blocks.1.ffn.layers.0.0.bias\n",
      "stages.1.blocks.1.ffn.layers.1.weight\n",
      "stages.1.blocks.1.ffn.layers.1.bias\n",
      "stages.1.downsample.norm.weight\n",
      "stages.1.downsample.norm.bias\n",
      "stages.2.blocks.0.norm1.weight\n",
      "stages.2.blocks.0.norm1.bias\n",
      "stages.2.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.0.attn.w_msa.proj.weight\n",
      "stages.2.blocks.0.attn.w_msa.proj.bias\n",
      "stages.2.blocks.0.norm2.weight\n",
      "stages.2.blocks.0.norm2.bias\n",
      "stages.2.blocks.0.ffn.layers.0.0.weight\n",
      "stages.2.blocks.0.ffn.layers.0.0.bias\n",
      "stages.2.blocks.0.ffn.layers.1.weight\n",
      "stages.2.blocks.0.ffn.layers.1.bias\n",
      "stages.2.blocks.1.norm1.weight\n",
      "stages.2.blocks.1.norm1.bias\n",
      "stages.2.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.1.attn.w_msa.proj.weight\n",
      "stages.2.blocks.1.attn.w_msa.proj.bias\n",
      "stages.2.blocks.1.norm2.weight\n",
      "stages.2.blocks.1.norm2.bias\n",
      "stages.2.blocks.1.ffn.layers.0.0.weight\n",
      "stages.2.blocks.1.ffn.layers.0.0.bias\n",
      "stages.2.blocks.1.ffn.layers.1.weight\n",
      "stages.2.blocks.1.ffn.layers.1.bias\n",
      "stages.2.blocks.2.norm1.weight\n",
      "stages.2.blocks.2.norm1.bias\n",
      "stages.2.blocks.2.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.2.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.2.attn.w_msa.proj.weight\n",
      "stages.2.blocks.2.attn.w_msa.proj.bias\n",
      "stages.2.blocks.2.norm2.weight\n",
      "stages.2.blocks.2.norm2.bias\n",
      "stages.2.blocks.2.ffn.layers.0.0.weight\n",
      "stages.2.blocks.2.ffn.layers.0.0.bias\n",
      "stages.2.blocks.2.ffn.layers.1.weight\n",
      "stages.2.blocks.2.ffn.layers.1.bias\n",
      "stages.2.blocks.3.norm1.weight\n",
      "stages.2.blocks.3.norm1.bias\n",
      "stages.2.blocks.3.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.3.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.3.attn.w_msa.proj.weight\n",
      "stages.2.blocks.3.attn.w_msa.proj.bias\n",
      "stages.2.blocks.3.norm2.weight\n",
      "stages.2.blocks.3.norm2.bias\n",
      "stages.2.blocks.3.ffn.layers.0.0.weight\n",
      "stages.2.blocks.3.ffn.layers.0.0.bias\n",
      "stages.2.blocks.3.ffn.layers.1.weight\n",
      "stages.2.blocks.3.ffn.layers.1.bias\n",
      "stages.2.blocks.4.norm1.weight\n",
      "stages.2.blocks.4.norm1.bias\n",
      "stages.2.blocks.4.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.4.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.4.attn.w_msa.proj.weight\n",
      "stages.2.blocks.4.attn.w_msa.proj.bias\n",
      "stages.2.blocks.4.norm2.weight\n",
      "stages.2.blocks.4.norm2.bias\n",
      "stages.2.blocks.4.ffn.layers.0.0.weight\n",
      "stages.2.blocks.4.ffn.layers.0.0.bias\n",
      "stages.2.blocks.4.ffn.layers.1.weight\n",
      "stages.2.blocks.4.ffn.layers.1.bias\n",
      "stages.2.blocks.5.norm1.weight\n",
      "stages.2.blocks.5.norm1.bias\n",
      "stages.2.blocks.5.attn.w_msa.qkv.weight\n",
      "stages.2.blocks.5.attn.w_msa.qkv.bias\n",
      "stages.2.blocks.5.attn.w_msa.proj.weight\n",
      "stages.2.blocks.5.attn.w_msa.proj.bias\n",
      "stages.2.blocks.5.norm2.weight\n",
      "stages.2.blocks.5.norm2.bias\n",
      "stages.2.blocks.5.ffn.layers.0.0.weight\n",
      "stages.2.blocks.5.ffn.layers.0.0.bias\n",
      "stages.2.blocks.5.ffn.layers.1.weight\n",
      "stages.2.blocks.5.ffn.layers.1.bias\n",
      "stages.2.downsample.norm.weight\n",
      "stages.2.downsample.norm.bias\n",
      "stages.3.blocks.0.norm1.weight\n",
      "stages.3.blocks.0.norm1.bias\n",
      "stages.3.blocks.0.attn.w_msa.qkv.weight\n",
      "stages.3.blocks.0.attn.w_msa.qkv.bias\n",
      "stages.3.blocks.0.attn.w_msa.proj.weight\n",
      "stages.3.blocks.0.attn.w_msa.proj.bias\n",
      "stages.3.blocks.0.norm2.weight\n",
      "stages.3.blocks.0.norm2.bias\n",
      "stages.3.blocks.0.ffn.layers.0.0.weight\n",
      "stages.3.blocks.0.ffn.layers.0.0.bias\n",
      "stages.3.blocks.0.ffn.layers.1.weight\n",
      "stages.3.blocks.0.ffn.layers.1.bias\n",
      "stages.3.blocks.1.norm1.weight\n",
      "stages.3.blocks.1.norm1.bias\n",
      "stages.3.blocks.1.attn.w_msa.qkv.weight\n",
      "stages.3.blocks.1.attn.w_msa.qkv.bias\n",
      "stages.3.blocks.1.attn.w_msa.proj.weight\n",
      "stages.3.blocks.1.attn.w_msa.proj.bias\n",
      "stages.3.blocks.1.norm2.weight\n",
      "stages.3.blocks.1.norm2.bias\n",
      "stages.3.blocks.1.ffn.layers.0.0.weight\n",
      "stages.3.blocks.1.ffn.layers.0.0.bias\n",
      "stages.3.blocks.1.ffn.layers.1.weight\n",
      "stages.3.blocks.1.ffn.layers.1.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "stages.0.blocks.0.attn.w_msa.relative_position_index\n",
      "stages.0.blocks.1.attn.w_msa.relative_position_index\n",
      "stages.1.blocks.0.attn.w_msa.relative_position_index\n",
      "stages.1.blocks.1.attn.w_msa.relative_position_index\n",
      "stages.2.blocks.0.attn.w_msa.relative_position_index\n",
      "stages.2.blocks.1.attn.w_msa.relative_position_index\n",
      "stages.2.blocks.2.attn.w_msa.relative_position_index\n",
      "stages.2.blocks.3.attn.w_msa.relative_position_index\n",
      "stages.2.blocks.4.attn.w_msa.relative_position_index\n",
      "stages.2.blocks.5.attn.w_msa.relative_position_index\n",
      "stages.3.blocks.0.attn.w_msa.relative_position_index\n",
      "stages.3.blocks.1.attn.w_msa.relative_position_index\n",
      "stages.0.blocks.1.attn_mask\n",
      "stages.1.blocks.1.attn_mask\n",
      "stages.2.blocks.1.attn_mask\n",
      "stages.2.blocks.3.attn_mask\n",
      "stages.2.blocks.5.attn_mask\n",
      "stages.0.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.0.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.1.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.1.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.2.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.3.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.4.attn.w_msa.relative_position_bias_table\n",
      "stages.2.blocks.5.attn.w_msa.relative_position_bias_table\n",
      "stages.3.blocks.0.attn.w_msa.relative_position_bias_table\n",
      "stages.3.blocks.1.attn.w_msa.relative_position_bias_table\n",
      "stages.0.downsample.reduction.weight\n",
      "stages.1.downsample.reduction.weight\n",
      "stages.2.downsample.reduction.weight\n"
     ]
    }
   ],
   "source": [
    "for i in mmseg.keys():\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mask2FormerConfig {\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"backbone\": null,\n",
       "  \"backbone_config\": {\n",
       "    \"depths\": [\n",
       "      2,\n",
       "      2,\n",
       "      6,\n",
       "      2\n",
       "    ],\n",
       "    \"drop_path_rate\": 0.3,\n",
       "    \"in_channels\": 3,\n",
       "    \"model_type\": \"swin\",\n",
       "    \"out_features\": [\n",
       "      \"stage1\",\n",
       "      \"stage2\",\n",
       "      \"stage3\",\n",
       "      \"stage4\"\n",
       "    ],\n",
       "    \"out_indices\": [\n",
       "      1,\n",
       "      2,\n",
       "      3,\n",
       "      4\n",
       "    ]\n",
       "  },\n",
       "  \"backbone_kwargs\": null,\n",
       "  \"class_weight\": 2.0,\n",
       "  \"common_stride\": 4,\n",
       "  \"decoder_layers\": 10,\n",
       "  \"dice_weight\": 5.0,\n",
       "  \"dim_feedforward\": 2048,\n",
       "  \"dropout\": 0.0,\n",
       "  \"encoder_feedforward_dim\": 1024,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"enforce_input_projection\": false,\n",
       "  \"feature_size\": 256,\n",
       "  \"feature_strides\": [\n",
       "    4,\n",
       "    8,\n",
       "    16,\n",
       "    32\n",
       "  ],\n",
       "  \"hidden_dim\": 256,\n",
       "  \"ignore_value\": 255,\n",
       "  \"importance_sample_ratio\": 0.75,\n",
       "  \"init_std\": 0.02,\n",
       "  \"init_xavier_std\": 1.0,\n",
       "  \"mask_feature_size\": 256,\n",
       "  \"mask_weight\": 5.0,\n",
       "  \"model_type\": \"mask2former\",\n",
       "  \"no_object_weight\": 0.1,\n",
       "  \"num_attention_heads\": 8,\n",
       "  \"num_hidden_layers\": 10,\n",
       "  \"num_queries\": 100,\n",
       "  \"output_auxiliary_logits\": null,\n",
       "  \"oversample_ratio\": 3.0,\n",
       "  \"pre_norm\": false,\n",
       "  \"train_num_points\": 12544,\n",
       "  \"transformers_version\": \"4.44.1\",\n",
       "  \"use_auxiliary_loss\": true,\n",
       "  \"use_pretrained_backbone\": false,\n",
       "  \"use_timm_backbone\": false\n",
       "}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DownloadConfig' object has no attribute 'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluate\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean_iou\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/evaluate/loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[0;32m--> 748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m import_main_class(evaluation_module\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[1;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[1;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[1;32m    761\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/evaluate/loading.py:680\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[0;32m--> 680\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    682\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hugging Face Hub either.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/evaluate/loading.py:633\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasurement\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubEvaluationModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluate-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/evaluate/loading.py:479\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# get script and other files\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_loading_script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# if there is no file found with current revision tag try to load main\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrevision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_SCRIPTS_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, SCRIPTS_VERSION) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/evaluate/loading.py:469\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.download_loading_script\u001b[0;34m(self, revision)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_config\u001b[38;5;241m.\u001b[39mdownload_desc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mdownload_desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading builder script\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openmmlab/lib/python3.8/site-packages/evaluate/utils/file_utils.py:185\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(url_or_filename)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m get_from_cache(\n\u001b[1;32m    176\u001b[0m         url_or_filename,\n\u001b[1;32m    177\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    178\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mforce_download,\n\u001b[1;32m    179\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[1;32m    180\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mresume_download,\n\u001b[1;32m    181\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39muser_agent,\n\u001b[1;32m    182\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mlocal_files_only,\n\u001b[1;32m    183\u001b[0m         use_etag\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39muse_etag,\n\u001b[1;32m    184\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m--> 185\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m,\n\u001b[1;32m    186\u001b[0m         download_desc\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mdownload_desc,\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DownloadConfig' object has no attribute 'token'"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
